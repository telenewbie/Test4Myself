AEC 模块 
## 直接集成 webrtc

问题: 
1. 输入时域 输出 时域 导致耗费过多的运算
2. 不能针对浮点进行预算，一定要转换成short类型进行运算 
3. 仅支持 16000 k ，10ms 一帧的数据， 目前主要用于 mic == ref 的场景
4. 单麦场景，通话场景 效果较好，双讲，识别场景 则需要专业的调参 才可
5. 对于 远端能量较强 近端能量较弱则 需要特殊处理【使用自己的elevoc webrtc版本 效果才更好】

优点: 现成方案，集成方便，

改进: 
1. 时域 进 ，频域出，这样最好
2. 可以 支持 float 的运算

## elevoc webrtc

问题:
1. 模型需要更换【耳机，pc，唤醒等不同的场景不同的模型】,导致接口不统一
2. 接口和 webrtc 的接口不同， 需要封装才可以

优点: 
1. 专人维护
2. 根据不同的场景 进行不同的训练

改进: 需要增加 适配层 兼容 不同 模型导致的接口不一致


### 已知情报
不同的模型 不同的方案

算法团队有自己维护的一套aec 不同与前面两套的方案

涉及的接口也是不一致的， 适配层很重要

目前 发现 针对不同的麦克风和参考信号的数目 有不一样的对外暴露的接口，而且模型等也是不一样的

现在 先从 多麦的方案 `VoiceManager`  中进行 提取 并进行集成, 查看下效果 

当然还有两套方案： 1. 是 针对pc 方案的 两个项目 ``PC_DUAL`` `PC` 这两个项目

更新：
频域进 频域出 
webrtc  时域进  时域 出

更新：
目前不是所有平台 都有相对应的 aec 版本库的，目前 ``VoiceManager`` 中的是 仅只有 Android的版本
，后期如果有需要再给个具体的版本吧

原来每个算法团队对外暴露的接口是不一样的啊 ， 我还以为只是 段总 和 算法团队 的接口不一致  ，原来 算法团队内部
的接口也不一致 啊

现在 的计划是 使用 ``PC_NS`` 的版本进行集成 测试 ，

至于 算法团队的接口 现在有两套  ``PC_DUAL_NS`` 和 `VoiceManager` 大概就是这样，所以需要做的就是
每个平台进行 验证， 先验证已有的 库吧


### 集成 ``PC_NS`` 感想
1. 几个 MIC 就执行几遍 AEC 的过程

 
对于 通话场景 尽量 做到 不改变采样率的 情况下 就能进行 aec 例如 直接对48000 的数据 进行处理

对于唤醒的场景 可以 对 输入的音频 进行 重采样 

如果 既有通话 的要求又有  唤醒的需求  则可以切换两套模型的方式进行 

关于aec

目前已知 在 对 48000  数据进行处理时 是 对 每一帧的数据 480 个字节的数据进行 拆成 3个子带 的方式 进行
每个自带的数据就是160 字节，然后在进行aec 的处理 ，
也就是说 webrtc 是支持 48000 数据的 aec 的，通过查看源码也能知道 有对 8000 到 48000 的数据 进行处理，
只是处理的方式不一样罢了。



 